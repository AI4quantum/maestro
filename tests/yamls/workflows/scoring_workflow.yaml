apiVersion: maestro/v1
kind: Workflow
metadata:
  name: evaluate workflow
  labels:
    app: example
spec:
  template:
    metadata:
      name: maestro-deployment
    prompt: What is the capital of the United States?
    steps:
      - name: dummy
        agent: test1
      - name: dummy2
        agent: test2
      - name: scoring
        agent: evaluate
        from: [prompt, dummy2]        # → run's first arg = original prompt, second arg = dummy's reply
        context:
          - "Washington, D.C. is the capital of the United States."  # → context for evaluation
        outputs:
          - answer               # → re‐emit the raw response downstream
